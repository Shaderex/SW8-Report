%!TEX root = ../../super_main.tex

\section{Deriving the Context from Sensors}
\label{sec:deriving_the_context_from_sensors}
This section describes how different sensors may contribute to capturing the context in which the participants exist. This includes investigating how common various sensors are, alongside an explanation of the nature of different types of sensors. Note that there might be differences in the quality of the sensors, since not all devices are using the exact same hardware.
% We only consider sensors that are commonly found in mobile devices and smart wearables compatible with Android. 

\subsection{Availability of Sensors}
The specifications of some popular smartphones and wearables have been analyzed, in order to discover which sensors are commonly available and how different types of devices can contribute. \tabref{tab:sensors_in_devices} gives an overview of which sensors are available from each of these devices. It can be seen that most smartphones contain many of the same sensors, with a few exceptions on the ambient light and barometer sensor. There seems to be more variation when considering smartwatches, as they contain many different sensors. This will have to be considered when a system is developed.

\input{content/problem_analysis/sensors_in_devices}

\subsection{Continuous and Reactive Sensors}
There exist many sensors where a single reading from them does not provide much value in terms of describing the context around a device. These types of continuous sensors would add more value by having a stream of measurements from them, meaning that change over time in these measurements captures the context better. Some of these sensors also have a reactive nature, meaning that it is actually the change in measurements that describes the context, which means that every reading is valuable. This section describes sensors that are of this continuous or reactive nature.

\begin{description}
	\item[Accelerometer] measures the acceleration of the device in three dimensions, which is also often together with the gyroscope sensor. The accelerometer is able to provide measurements for the acceleration of the wearer or user along the three physical axes, typically measured in $m/s^2$.
	\item[Gyroscope] measures the speed of rotation of the device in space. The gyroscope provides an idea of the orientation of the device relative to Earth's gravitational pull. The rotation of the gyroscope is measured on all three axises as rotation velocity in $rad/s$.
	\item[Magnetometer] is able determine the orientation of the device relative to the Earth's magnetic field. This sensor can, in combination with the accelerometer be used to provide readings like that of a compass. The magnetometer measures the magnetic influence on all threes axises in $\mu T$ (microtesla).
	\item[Barometer] approximates the air pressure, in $hPa$ or $mbar$, around the device. The readings from a barometer can be used to estimate the altitude of the device, but this may fluctuate based on the location and the current weather conditions.
    \item[Optical Heart Rate Sensor] estimates the heart rate, using a light source and a light sensitive sensor. Heart rates are measured in beats per minute. It can be used to detected elevated heart rate levels for instance caused by exercising or heightened levels of stress. Heart rate monitoring can also be used estimate the quality of ones sleep \parencite{guardian_fitness_tracker_rem_sleep}. 
    \item[Skin Temperature Sensor] measures the temperature of skin that touches the device, given in some unit of temperature, usually degrees Celsius. This can possibly indicate environmental effects on the body temperature, exercising, fever, etc.
    \item[Galvanic Skin Response Sensor] measures the conductivity of the surface against the device. This can indicate whether or not a person is sweating, or more generally the moisture level on a surface. This sensor is commonly used to infer whether a wearable device is being worn at the moment, and its output is measured in ohm ($\Omega$).
    \item[Proximity Sensor] can estimate how close the device is to the nearest object facing the sensor by using an infrared beam. This estimation often has higher accuracy at lower distances. The distance is measured in $cm$. Some devices, however, do not measure the distance with a precise value, but instead returns a binary value that represent ``near'' or ``far''. This sensor is commonly used to turn off the display when the device is placed in the pocket or is held against the ear.
    \item[Ambient Light Sensor] makes it possible to measure the illumination surrounding the device in $lx$ (lux). This is commonly used to regulate the background light of the device's screen.
    \item[Ultraviolet Sensor] measures the ultraviolet (UV) radiation hitting the device. This is useful for estimating whether a person is inside or outside. It can also be used to estimate whether a person has spent too much time outside, and thereby in risk of sunburns or skin cancer, by accumulating readings of UV radiation of an entire day. As an example of the output of a UV sensor, the Microsoft Band 2 outputs the following discrete values: none, low, medium, high, and very high, which corresponds to different levels of UV. 
\end{description}

\subsection{On-Demand Sensors}
On-demand sensors are sensors that do not provide a stream of information, but have to be requested whenever a measurement is needed. Measurements from these types of sensors are typically more expensive in terms of battery consumption and computation. An on demand reading can only be given asynchronously, as the device would first have to contact multiple information providers, such as cell towers or Global Positioning System (GPS) satellites, and over time reach a sufficiently accurate reading. To improve efficiency, the latest readings are, for example in Android, cached, which allows quick access to the most recent result fetched by another application.

\begin{description}
    \item[Wi-Fi] in mobile devices can be used for more than just pure data communication with the local network and the Internet. Information about access points and the signal to these access points can for instance be used to approximate an indoor location. Features derived from Wi-Fi networks could, for instance, be reachable access point names, their communication standards, and signal strengths. 
    \item[Global Positioning System] approximates the latitude and longitude of the device based on satellite triangulation. Most modern mobile devices use Assisted GPS (A-GPS), meaning that the GPS is assisted by the cellular network. The rough positioning is based on the cellular network and the accurate position is triangulated using GPS satellites. Some systems can also provide estimated information about speed and bearing of the device.
    \item[Cellular Networking] can, similarly to Wi-Fi, be used for more than pure communication as data from different mobile towers and the signal strength to these towers can be useful besides communication. Potentially interesting features could be country code, network code, cell identity (mast identity), cell tower technology type, and signal strength.
\end{description}

We have briefly looked at the availability of various sensors in different smart devices, and it generally seems like most devices have many of the same sensors. This means, in relation to this project, that we can choose to develop a solution for either iPhone, Android or Windows Phone and their related wearables without limiting the available sensors. A context can, at the same time, be measured by multiple sensory devices in order to increase the accuracy of the data, which suggests combining outputs from multiple of the examined sensory devices. 
\\\\
Some of the data sources are overlapping in terms of what they capture about the context, and we have therefore initially chosen not to include cellular networking as a data source directly. There is a lot of data to be found from this sensor, but the features and the layout of the data differs depending on which cellular technology the cell tower supports, which makes it slightly difficult to implement. The location of the user is already indirectly available through A-GPS and cellular positioning, which is the foundation for our decision.
\\\\
There are also other available sensors that we have not yet taken a look at in order to describe contexts, such as Bluetooth, screen wake time, use of applications, etc. We will not exclude the possibility of implementing these sensors in the future during the development, but we think the sensors from \tabref{tab:sensors_in_devices} describe an initial sensor context that we can use in order to build a base product and we will therefore not implement support for the remaining sensors.